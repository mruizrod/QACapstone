{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../src\")\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llama2 import Llama2\n",
    "from src.nlp_base import NLP_base\n",
    "from src.nlp_langchain import NLP_langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama2 = Llama2(\n",
    "    input_files=[\"../data/pdf/am-mid-year-outlook-2024.pdf\"],\n",
    "    verbose=False,\n",
    "); llama2.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nlp-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_base = NLP_base(\n",
    "    input_files=[\"../data/pdf/am-mid-year-outlook-2024.pdf\"],\n",
    "    verbose=False,\n",
    "); nlp_base.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load Manual Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.read_csv(\"../data/testQ.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [21:54<00:00, 87.64s/it] \n"
     ]
    }
   ],
   "source": [
    "sim_q_r, sim_a_r = [], []\n",
    "iterator = questions[[\"Question\", \"Answer\"]].to_records(index=False)\n",
    "for q, a in tqdm(iterator):\n",
    "    scores_q, scores_a = [], []\n",
    "    for _ in range(10):\n",
    "        response, score = llama2.answer(q)\n",
    "        scores_q.append(score)\n",
    "        scores_a.append(cosine_similarity(\n",
    "            [llama2.embed_model._embed(a)], \n",
    "            [llama2.embed_model._embed(str(response))],\n",
    "        )[0][0])\n",
    "    sim_q_r.append(np.mean(scores_q))\n",
    "    sim_a_r.append(np.mean(scores_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_llama2 = questions[[\"Question\"]].copy()\n",
    "res_llama2[\"model\"] = \"llama2\"\n",
    "res_llama2[\"similarity_response_question\"] = sim_q_r\n",
    "res_llama2[\"similarity_response_answer\"] = sim_a_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:11<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "sim_q_r, sim_a_r = [], []\n",
    "iterator = questions[[\"Question\", \"Answer\"]].to_records(index=False)\n",
    "for q, a in tqdm(iterator):\n",
    "    scores_q, scores_a = [], []\n",
    "    for _ in range(10):\n",
    "        response, score = nlp_base.answer(q)\n",
    "        scores_q.append(score)\n",
    "        scores_a.append(cosine_similarity(\n",
    "            [llama2.embed_model._embed(a)], \n",
    "            [llama2.embed_model._embed(str(response))],\n",
    "        )[0][0])\n",
    "    sim_q_r.append(np.mean(scores_q))\n",
    "    sim_a_r.append(np.mean(scores_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_nlp_base = questions[[\"Question\"]].copy()\n",
    "res_nlp_base[\"model\"] = \"nlp_base\"\n",
    "res_nlp_base[\"similarity_response_question\"] = sim_q_r\n",
    "res_nlp_base[\"similarity_response_answer\"] = sim_a_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([res_llama2, res_nlp_base]).reset_index()\n",
    "res.sort_values([\"index\", \"model\"], inplace=True, ignore_index=True)\n",
    "res.drop(\"index\", axis=1, inplace=True)\n",
    "res.to_csv(\"./test_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of Columns\n",
    "- `similarity_response_answer`: cosine similarity between response and manually labeled answer\n",
    "- `similarity_response_question`: cosine similarity between response and input question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>model</th>\n",
       "      <th>similarity_response_question</th>\n",
       "      <th>similarity_response_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How much has Norway's policy rate changed over...</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.860554</td>\n",
       "      <td>0.607631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How much has Norway's policy rate changed over...</td>\n",
       "      <td>nlp_base</td>\n",
       "      <td>0.682312</td>\n",
       "      <td>0.595814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is the shift to higher interest rates posing c...</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.880874</td>\n",
       "      <td>0.899823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is the shift to higher interest rates posing c...</td>\n",
       "      <td>nlp_base</td>\n",
       "      <td>0.754041</td>\n",
       "      <td>0.860071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can small caps finally outperform?</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.796116</td>\n",
       "      <td>0.853054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can small caps finally outperform?</td>\n",
       "      <td>nlp_base</td>\n",
       "      <td>0.668756</td>\n",
       "      <td>0.796996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is “normal” for private equity?</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.847603</td>\n",
       "      <td>0.876351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is “normal” for private equity?</td>\n",
       "      <td>nlp_base</td>\n",
       "      <td>0.755375</td>\n",
       "      <td>0.792823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the key takeaway of Goldman's mid-year...</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.830780</td>\n",
       "      <td>0.712899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What is the key takeaway of Goldman's mid-year...</td>\n",
       "      <td>nlp_base</td>\n",
       "      <td>0.761847</td>\n",
       "      <td>0.771109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Are investment theses predicated on the contin...</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.848791</td>\n",
       "      <td>0.814979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Are investment theses predicated on the contin...</td>\n",
       "      <td>nlp_base</td>\n",
       "      <td>0.728865</td>\n",
       "      <td>0.784294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What might the US election mean for the Inflat...</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.817683</td>\n",
       "      <td>0.882307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What might the US election mean for the Inflat...</td>\n",
       "      <td>nlp_base</td>\n",
       "      <td>0.727494</td>\n",
       "      <td>0.883164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How should investors think about healthcare in...</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.827672</td>\n",
       "      <td>0.924353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How should investors think about healthcare in...</td>\n",
       "      <td>nlp_base</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.837326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What are the potential market implications of ...</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.915193</td>\n",
       "      <td>0.884455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What are the potential market implications of ...</td>\n",
       "      <td>nlp_base</td>\n",
       "      <td>0.786234</td>\n",
       "      <td>0.790760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>How will AI shape real estate and infrastructure?</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.857155</td>\n",
       "      <td>0.932574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How will AI shape real estate and infrastructure?</td>\n",
       "      <td>nlp_base</td>\n",
       "      <td>0.793148</td>\n",
       "      <td>0.838533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What opportunities are emerging at the interse...</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.838666</td>\n",
       "      <td>0.850416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What opportunities are emerging at the interse...</td>\n",
       "      <td>nlp_base</td>\n",
       "      <td>0.716624</td>\n",
       "      <td>0.864103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What events were attributed to spikes in the G...</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.908404</td>\n",
       "      <td>0.797973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What events were attributed to spikes in the G...</td>\n",
       "      <td>nlp_base</td>\n",
       "      <td>0.765989</td>\n",
       "      <td>0.677817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What are current levels of US debt held by the...</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.885308</td>\n",
       "      <td>0.751348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What are current levels of US debt held by the...</td>\n",
       "      <td>nlp_base</td>\n",
       "      <td>0.836312</td>\n",
       "      <td>0.727579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>What was the lowest level of US debt held by t...</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.839464</td>\n",
       "      <td>0.769584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What was the lowest level of US debt held by t...</td>\n",
       "      <td>nlp_base</td>\n",
       "      <td>0.745069</td>\n",
       "      <td>0.750762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What happened in the first six months of 2024 ...</td>\n",
       "      <td>llama2</td>\n",
       "      <td>0.808109</td>\n",
       "      <td>0.874615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What happened in the first six months of 2024 ...</td>\n",
       "      <td>nlp_base</td>\n",
       "      <td>0.682883</td>\n",
       "      <td>0.812946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Question     model  \\\n",
       "0   How much has Norway's policy rate changed over...    llama2   \n",
       "1   How much has Norway's policy rate changed over...  nlp_base   \n",
       "2   Is the shift to higher interest rates posing c...    llama2   \n",
       "3   Is the shift to higher interest rates posing c...  nlp_base   \n",
       "4                  Can small caps finally outperform?    llama2   \n",
       "5                  Can small caps finally outperform?  nlp_base   \n",
       "6                What is “normal” for private equity?    llama2   \n",
       "7                What is “normal” for private equity?  nlp_base   \n",
       "8   What is the key takeaway of Goldman's mid-year...    llama2   \n",
       "9   What is the key takeaway of Goldman's mid-year...  nlp_base   \n",
       "10  Are investment theses predicated on the contin...    llama2   \n",
       "11  Are investment theses predicated on the contin...  nlp_base   \n",
       "12  What might the US election mean for the Inflat...    llama2   \n",
       "13  What might the US election mean for the Inflat...  nlp_base   \n",
       "14  How should investors think about healthcare in...    llama2   \n",
       "15  How should investors think about healthcare in...  nlp_base   \n",
       "16  What are the potential market implications of ...    llama2   \n",
       "17  What are the potential market implications of ...  nlp_base   \n",
       "18  How will AI shape real estate and infrastructure?    llama2   \n",
       "19  How will AI shape real estate and infrastructure?  nlp_base   \n",
       "20  What opportunities are emerging at the interse...    llama2   \n",
       "21  What opportunities are emerging at the interse...  nlp_base   \n",
       "22  What events were attributed to spikes in the G...    llama2   \n",
       "23  What events were attributed to spikes in the G...  nlp_base   \n",
       "24  What are current levels of US debt held by the...    llama2   \n",
       "25  What are current levels of US debt held by the...  nlp_base   \n",
       "26  What was the lowest level of US debt held by t...    llama2   \n",
       "27  What was the lowest level of US debt held by t...  nlp_base   \n",
       "28  What happened in the first six months of 2024 ...    llama2   \n",
       "29  What happened in the first six months of 2024 ...  nlp_base   \n",
       "\n",
       "    similarity_response_question  similarity_response_answer  \n",
       "0                       0.860554                    0.607631  \n",
       "1                       0.682312                    0.595814  \n",
       "2                       0.880874                    0.899823  \n",
       "3                       0.754041                    0.860071  \n",
       "4                       0.796116                    0.853054  \n",
       "5                       0.668756                    0.796996  \n",
       "6                       0.847603                    0.876351  \n",
       "7                       0.755375                    0.792823  \n",
       "8                       0.830780                    0.712899  \n",
       "9                       0.761847                    0.771109  \n",
       "10                      0.848791                    0.814979  \n",
       "11                      0.728865                    0.784294  \n",
       "12                      0.817683                    0.882307  \n",
       "13                      0.727494                    0.883164  \n",
       "14                      0.827672                    0.924353  \n",
       "15                      0.784810                    0.837326  \n",
       "16                      0.915193                    0.884455  \n",
       "17                      0.786234                    0.790760  \n",
       "18                      0.857155                    0.932574  \n",
       "19                      0.793148                    0.838533  \n",
       "20                      0.838666                    0.850416  \n",
       "21                      0.716624                    0.864103  \n",
       "22                      0.908404                    0.797973  \n",
       "23                      0.765989                    0.677817  \n",
       "24                      0.885308                    0.751348  \n",
       "25                      0.836312                    0.727579  \n",
       "26                      0.839464                    0.769584  \n",
       "27                      0.745069                    0.750762  \n",
       "28                      0.808109                    0.874615  \n",
       "29                      0.682883                    0.812946  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
