{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianyuyang/Desktop/CMU MSCF Courses/Mini 5/ML_Capstone/QACapstone/llama_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "base_dir = os.path.abspath(\"..\")\n",
    "sys.path.append(base_dir) \n",
    "sys.path.append(os.path.join(base_dir, \"src\"))  \n",
    "data_path = os.path.join(base_dir, \"data\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from src.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from llama2 import Llama2\n",
    "from llama2_general import Llama2_General\n",
    "\n",
    "from nlp_langchain import NLP_langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fcd51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"What is the key takeaway of Goldman’s mid-year outlook 2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0097bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance_text = f\"\"\"\n",
    "Objective:\n",
    "I will provide you with a task or description. Your job is to create a single, well-structured, actionable prompt that effectively guides another LLMto perform the task.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "\t1.\tDirect Prompt Creation:\n",
    "\t•\tDo not include explanations or steps about how you engineered the prompt—just provide the final prompt.\n",
    "\t2.\tInclude Relevant Context:\n",
    "\t•\tIf the task seems to rely on information from a document or dataset, assume the LLM has access to that data.\n",
    "\t•\tMake sure the engineered prompt explicitly refers to that document or dataset to guide the real LLM effectively.\n",
    "\t3.\tClear and Specific Instructions:\n",
    "\t•\tEnsure the prompt is concise, grammatically correct, and avoids ambiguity.\n",
    "\t•\tSpecify the desired format, tone, or any constraints.\n",
    "\t4.\tIterative Refinement:\n",
    "\t•\tIf a single prompt isn’t sufficient, suggest breaking the task into subtasks within the same prompt.\n",
    "\n",
    "Examples\n",
    "\n",
    "Input:\n",
    "\n",
    "“Summarize a financial report and identify key trends.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Using the financial report provided, summarize the key trends in revenue, expenses, and profit margins over the past quarter. Highlight any significant changes or patterns in the data. Present your response in a professional tone and limit it to 3-5 sentences.”\n",
    "\n",
    "Input:\n",
    "\n",
    "“Analyze customer reviews for sentiment.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Analyze the customer reviews provided and classify the sentiment as positive, negative, or neutral. Provide a one-sentence explanation for each classification, citing specific phrases from the reviews.”\n",
    "\n",
    "Input:\n",
    "\n",
    "“Generate a Python function to calculate portfolio variance.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Write a Python function that calculates the variance of a portfolio given a list of asset weights and their covariance matrix. Include detailed inline comments explaining each step of the function.”\n",
    "\n",
    "Final Instructions:\n",
    "When I give you a task, respond only with the final engineered prompt. If the task seems to depend on specific documents or datasets, explicitly reference them in the prompt to guide the LLM (the real one) effectively. Do not include any explanations or additional steps—just the prompt.\n",
    "\n",
    "\n",
    "<Prompt: {user_prompt}>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f8c0070",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_eng_llm = Llama2_General(verbose=False)\n",
    "\n",
    "engineered_prompt, score = prompt_eng_llm.answer(guidance_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1256149a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"The key takeaway of Goldman's mid-year outlook 2024 is...\",\n",
       " 0.586805687935153)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered_prompt, score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319ed1a0",
   "metadata": {},
   "source": [
    "## Feed into the QA LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744f4dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key takeaway of Goldman Sachs Asset Management's mid-year outlook 2024 is that the macroeconomic cycle is adjusting, and the world remains in an era of profound geopolitical change. Despite considerable progress in disinflation, the path to interest rate normalization is lengthening, highlighting the need for active and dynamic investment strategies. Balanced allocations and hedging strategies can potentially add resilience to portfolios amid unstable geopolitics and election-related uncertainty. The firm remains focused on key structural forces, including decarbonization, digitization, deglobalization, destabilization in geopolitics, and demographic aging, which transcend economic and election cycles and offer opportunities for value creation in private market strategies.\n"
     ]
    }
   ],
   "source": [
    "model = \"llama2\"\n",
    "parser = \"llamaparse\"\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    parser=parser, model=model,\n",
    "    data_path=data_path, verbose=False,\n",
    "); \n",
    "pipeline.train()\n",
    "\n",
    "response, score = pipeline.answer(engineered_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690b822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77e8a142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Using the provided financial report, predict the anticipated fed funds rate at the end of 2024 based on historical trends and current economic indicators. Provide a clear and concise explanation for your prediction.\" 0.6428836102975553\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Tell me the anticipated rate of Fed at the end of 2024\"\n",
    "\n",
    "guidance_text = f\"\"\"\n",
    "Objective:\n",
    "I will provide you with a task or description. Your job is to output a single, well-structured, actionable prompt that effectively guides another LLMto perform the task.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "\t1.\tDirect Prompt Creation:\n",
    "\t•\tDo not include explanations or steps about how you engineered the prompt—just provide the final prompt.\n",
    "\t2.\tInclude Relevant Context:\n",
    "\t•\tIf the task seems to rely on information from a document or dataset, assume the LLM has access to that data.\n",
    "\t•\tMake sure the engineered prompt explicitly refers to that document or dataset to guide the real LLM effectively.\n",
    "\t3.\tClear and Specific Instructions:\n",
    "\t•\tEnsure the prompt is concise, grammatically correct, and avoids ambiguity.\n",
    "\t•\tSpecify the desired format, tone, or any constraints.\n",
    "\t4.\tIterative Refinement:\n",
    "\t•\tIf a single prompt isn't sufficient, suggest breaking the task into subtasks within the same prompt.\n",
    "\n",
    "Examples\n",
    "\n",
    "Input:\n",
    "\n",
    "“Summarize a financial report and identify key trends.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Using the financial report provided, summarize the key trends in revenue, expenses, and profit margins over the past quarter. Highlight any significant changes or patterns in the data. Present your response in a professional tone and limit it to 3-5 sentences.”\n",
    "\n",
    "Input:\n",
    "\n",
    "“Analyze customer reviews for sentiment.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Analyze the customer reviews provided and classify the sentiment as positive, negative, or neutral. Provide a one-sentence explanation for each classification, citing specific phrases from the reviews.”\n",
    "\n",
    "Input:\n",
    "\n",
    "“Generate a Python function to calculate portfolio variance.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Write a Python function that calculates the variance of a portfolio given a list of asset weights and their covariance matrix. Include detailed inline comments explaining each step of the function.”\n",
    "\n",
    "Final Instructions:\n",
    "When I give you a task, respond only with the final engineered prompt. If the task seems to depend on specific documents or datasets, explicitly reference them in the prompt to guide the LLM (the real one) effectively. Do not include any explanations or additional steps—just the prompt.\n",
    "\n",
    "\n",
    "<Prompt: {user_prompt}>\n",
    "\"\"\"\n",
    "\n",
    "prompt_eng_llm = Llama2_General(verbose=False)\n",
    "\n",
    "engineered_prompt, score = prompt_eng_llm.answer(guidance_text)\n",
    "print(engineered_prompt, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ffaed5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided in the financial report, it is difficult to make a precise prediction of the anticipated fed funds rate at the end of 2024. However, we can analyze historical trends and current economic indicators to provide an informed view.\n",
      "\n",
      "Historically, when central banks have engaged in rate-cutting cycles, it has been due to disinflationary pressures or economic downturns. Currently, the economy is experiencing a slowdown in growth, with inflation persisting at higher levels than in previous years. This suggests that there may be a need for monetary policy accommodation to support the economy.\n",
      "\n",
      "However, without clear evidence of economic deceleration or signs of a potential recession, it is unlikely that central banks will embark on a deep rate-cutting cycle. Instead, we may see a shallow adjustment cut or hikes or no cuts, depending on the specific circumstances.\n",
      "\n",
      "Using the SOFR curve provided in the report, we can estimate the anticipated fed funds rate at the end of 2024 based on the current trajectory of economic indicators. While there is uncertainty around the timing and pace of policy shifts, our analysis suggests that the fed funds rate may be in the range of 2.75-4.25% by the end of 2024, with a bias towards the lower end of this range given the current economic conditions.\n",
      "\n",
      "In conclusion, while there are mixed signals in the current economic environment, our analysis suggests that the anticipated fed funds rate at the end of 2024 is likely to be in the range of 2.75-4.25%. However, it is important to note that this prediction is subject to change based on future developments and evolving expectations around monetary policy.\n"
     ]
    }
   ],
   "source": [
    "model = \"llama2\"\n",
    "parser = \"llamaparse\"\n",
    "\n",
    "pipeline = Pipeline(\n",
    "                    parser=parser, model=model,\n",
    "                    data_path=data_path, verbose=False,\n",
    "                ); \n",
    "pipeline.train()\n",
    "\n",
    "response, score = pipeline.answer(engineered_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0a043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47fb5aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Based on the documents provided, what is your prediction for the anticipated fed funds rate at the end of 2024?\" 0.6399109179979479\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"Tell me the anticipated rate of Fed at the end of 2024\"\n",
    "\n",
    "guidance_text = f\"\"\"\n",
    "Objective:\n",
    "I will provide you with a task or description. Your job is to output a single, well-structured, actionable prompt that effectively guides another LLMto perform the task.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "\t1.\tDirect Prompt Creation:\n",
    "\t•\tDo not include explanations or steps about how you engineered the prompt—just provide the final prompt.\n",
    "\t2.\tInclude Relevant Context:\n",
    "\t•\tIf the task seems to rely on information from a document or dataset, assume the LLM has access to that data.\n",
    "\t•\tMake sure the engineered prompt explicitly refers to that document or dataset to guide the real LLM effectively.\n",
    "\t3.\tClear and Specific Instructions:\n",
    "\t•\tEnsure the prompt is concise, grammatically correct, and avoids ambiguity.\n",
    "\t•\tSpecify the desired format, tone, or any constraints.\n",
    "\t4.\tIterative Refinement:\n",
    "\t•\tIf a single prompt isn't sufficient, suggest breaking the task into subtasks within the same prompt.\n",
    "\n",
    "Examples\n",
    "\n",
    "Input:\n",
    "\n",
    "“Summarize a financial report and identify key trends.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Using the financial report provided, summarize the key trends in revenue, expenses, and profit margins over the past quarter. Highlight any significant changes or patterns in the data. Present your response in a professional tone and limit it to 3-5 sentences.”\n",
    "\n",
    "Input:\n",
    "\n",
    "“Analyze customer reviews for sentiment.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Analyze the customer reviews provided and classify the sentiment as positive, negative, or neutral. Provide a one-sentence explanation for each classification, citing specific phrases from the reviews.”\n",
    "\n",
    "Input:\n",
    "\n",
    "“Generate a Python function to calculate portfolio variance.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Write a Python function that calculates the variance of a portfolio given a list of asset weights and their covariance matrix. Include detailed inline comments explaining each step of the function.”\n",
    "\n",
    "Final Instructions:\n",
    "When I give you a task, respond only with the final engineered prompt. If the task seems to depend on specific documents or datasets, explicitly reference them in the prompt to guide the LLM (the real one) effectively. Do not include any explanations or additional steps—just the prompt.\n",
    "\n",
    "\n",
    "<Prompt: {user_prompt}>\n",
    "\"\"\"\n",
    "\n",
    "prompt_eng_llm = Llama2_General(verbose=False)\n",
    "\n",
    "engineered_prompt, score = prompt_eng_llm.answer(guidance_text)\n",
    "print(engineered_prompt, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef648715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9677f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Tell me the anticipated rate of Fed at the end of 2024, and where you found the info, by directly looking it up in the provided information.\"\n",
    "\n",
    "guidance_text = f\"\"\"\n",
    "Objective:\n",
    "I will provide you with a task or description. Your job is to output a single, well-structured, actionable prompt that effectively guides another LLMto perform the task.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "\t1.\tDirect Prompt Creation:\n",
    "\t•\tDo not include explanations or steps about how you engineered the prompt—just provide the final prompt.\n",
    "\t2.\tInclude Relevant Context:\n",
    "\t•\tIf the task seems to rely on information from a document or dataset, assume the LLM has access to that data.\n",
    "\t•\tMake sure the engineered prompt explicitly refers to that document or dataset to guide the real LLM effectively.\n",
    "\t3.\tClear and Specific Instructions:\n",
    "\t•\tEnsure the prompt is concise, grammatically correct, and avoids ambiguity.\n",
    "\t•\tSpecify the desired format, tone, or any constraints.\n",
    "\t4.\tIterative Refinement:\n",
    "\t•\tIf a single prompt isn't sufficient, suggest breaking the task into subtasks within the same prompt.\n",
    "\n",
    "Examples\n",
    "\n",
    "Input:\n",
    "\n",
    "“Summarize a financial report and identify key trends.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Using the financial report provided, summarize the key trends in revenue, expenses, and profit margins over the past quarter. Highlight any significant changes or patterns in the data. Present your response in a professional tone and limit it to 3-5 sentences.”\n",
    "\n",
    "Input:\n",
    "\n",
    "“Analyze customer reviews for sentiment.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Analyze the customer reviews provided and classify the sentiment as positive, negative, or neutral. Provide a one-sentence explanation for each classification, citing specific phrases from the reviews.”\n",
    "\n",
    "Input:\n",
    "\n",
    "“Generate a Python function to calculate portfolio variance.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Write a Python function that calculates the variance of a portfolio given a list of asset weights and their covariance matrix. Include detailed inline comments explaining each step of the function.”\n",
    "\n",
    "Final Instructions:\n",
    "When I give you a task, respond only with the final engineered prompt. If the task seems to depend on specific documents or datasets, explicitly reference them in the prompt to guide the LLM (the real one) effectively. Do not include any explanations or additional steps—just the prompt.\n",
    "\n",
    "\n",
    "<Prompt: {user_prompt}>\n",
    "\"\"\"\n",
    "\n",
    "prompt_eng_llm = Llama2_General(verbose=False)\n",
    "\n",
    "engineered_prompt, score = prompt_eng_llm.answer(guidance_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7424fd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"Based on the provided information, can you please provide the anticipated federal funds rate at the end of 2024? Please cite the source or document where you found this information.\"',\n",
       " 0.635474304853177)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered_prompt, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38357bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context information, the anticipated federal funds rate at the end of 2024 is 4.75-5% as stated in the Central Bank Snapshot section under the Federal Reserve's outlook. This information can be found on page 3 of the document.\n"
     ]
    }
   ],
   "source": [
    "model = \"llama2\"\n",
    "parser = \"llamaparse\"\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    parser=parser, model=model,\n",
    "    data_path=data_path, verbose=False,\n",
    "); \n",
    "pipeline.train()\n",
    "\n",
    "response, score = pipeline.answer(engineered_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2771268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context information provided, the anticipated rate of the Federal Reserve (Fed) at the end of 2024 is 4.75-5%. This information can be found in the third bullet point of the \"Central Bank Snapshot\" section, where it is stated that \"We think the Fed may initiate a rate cut in September considering recent disinflation progress and cooling of the labor market, followed by a further rate cut in December. Anticipated rate at end-2024: 4.75-5%.\"\n"
     ]
    }
   ],
   "source": [
    "model = \"llama2\"\n",
    "parser = \"llamaparse\"\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    parser=parser, model=model,\n",
    "    data_path=data_path, verbose=False,\n",
    "); \n",
    "pipeline.train()\n",
    "\n",
    "response, score = pipeline.answer(user_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1fb99a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the anticipated rate of Fed at the end of 2024, and where you found the info, by directly looking it up in the provided information.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b404ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
