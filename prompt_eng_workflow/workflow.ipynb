{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianyuyang/Desktop/CMU MSCF Courses/Mini 5/ML_Capstone/QACapstone/llama_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "base_dir = os.path.abspath(\"..\")\n",
    "sys.path.append(base_dir) \n",
    "sys.path.append(os.path.join(base_dir, \"src\"))  \n",
    "data_path = os.path.join(base_dir, \"data\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from src.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from llama2 import Llama2\n",
    "from llama2_general import Llama2_General\n",
    "\n",
    "from nlp_langchain import NLP_langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fcd51dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"What is the key takeaway of Goldman’s mid-year outlook 2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0097bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "guidance_text = f\"\"\"\n",
    "Objective:\n",
    "I will provide you with a task or description. Your job is to create a single, well-structured, actionable prompt that effectively guides another LLMto perform the task.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "\t1.\tDirect Prompt Creation:\n",
    "\t•\tDo not include explanations or steps about how you engineered the prompt—just provide the final prompt.\n",
    "\t2.\tInclude Relevant Context:\n",
    "\t•\tIf the task seems to rely on information from a document or dataset, assume the LLM has access to that data.\n",
    "\t•\tMake sure the engineered prompt explicitly refers to that document or dataset to guide the real LLM effectively.\n",
    "\t3.\tClear and Specific Instructions:\n",
    "\t•\tEnsure the prompt is concise, grammatically correct, and avoids ambiguity.\n",
    "\t•\tSpecify the desired format, tone, or any constraints.\n",
    "\t4.\tIterative Refinement:\n",
    "\t•\tIf a single prompt isn’t sufficient, suggest breaking the task into subtasks within the same prompt.\n",
    "\n",
    "Examples\n",
    "\n",
    "Input:\n",
    "\n",
    "“Summarize a financial report and identify key trends.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Using the financial report provided, summarize the key trends in revenue, expenses, and profit margins over the past quarter. Highlight any significant changes or patterns in the data. Present your response in a professional tone and limit it to 3-5 sentences.”\n",
    "\n",
    "Input:\n",
    "\n",
    "“Analyze customer reviews for sentiment.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Analyze the customer reviews provided and classify the sentiment as positive, negative, or neutral. Provide a one-sentence explanation for each classification, citing specific phrases from the reviews.”\n",
    "\n",
    "Input:\n",
    "\n",
    "“Generate a Python function to calculate portfolio variance.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Write a Python function that calculates the variance of a portfolio given a list of asset weights and their covariance matrix. Include detailed inline comments explaining each step of the function.”\n",
    "\n",
    "Final Instructions:\n",
    "When I give you a task, respond only with the final engineered prompt. If the task seems to depend on specific documents or datasets, explicitly reference them in the prompt to guide the LLM (the real one) effectively. Do not include any explanations or additional steps—just the prompt.\n",
    "\n",
    "\n",
    "<Prompt: {user_prompt}>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f8c0070",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_eng_llm = Llama2_General(verbose=False)\n",
    "\n",
    "engineered_prompt, score = prompt_eng_llm.answer(guidance_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1256149a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"The key takeaway of Goldman's mid-year outlook 2024 is...\",\n",
       " 0.586805687935153)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered_prompt, score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319ed1a0",
   "metadata": {},
   "source": [
    "## Feed into the QA LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "744f4dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key takeaway of Goldman Sachs Asset Management's mid-year outlook 2024 is that the macroeconomic cycle is adjusting, and the world remains in an era of profound geopolitical change. Despite considerable progress in disinflation, the path to interest rate normalization is lengthening, highlighting the need for active and dynamic investment strategies. Balanced allocations and hedging strategies can potentially add resilience to portfolios amid unstable geopolitics and election-related uncertainty. The firm remains focused on key structural forces, including decarbonization, digitization, deglobalization, destabilization in geopolitics, and demographic aging, which transcend economic and election cycles and offer opportunities for value creation in private market strategies.\n"
     ]
    }
   ],
   "source": [
    "model = \"llama2\"\n",
    "parser = \"llamaparse\"\n",
    "\n",
    "pipeline = Pipeline(\n",
    "                    parser=parser, model=model,\n",
    "                    data_path=data_path, verbose=False,\n",
    "                ); \n",
    "pipeline.train()\n",
    "\n",
    "response, score = pipeline.answer(engineered_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9677f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"Tell me the anticipated rate of Fed at the end of 2024, and where you found the info, by directly looking it up in the provided information.\"\n",
    "\n",
    "guidance_text = f\"\"\"\n",
    "Objective:\n",
    "I will provide you with a task or description. Your job is to output a single, well-structured, actionable prompt that effectively guides another LLMto perform the task.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "\t1.\tDirect Prompt Creation:\n",
    "\t•\tDo not include explanations or steps about how you engineered the prompt—just provide the final prompt.\n",
    "\t2.\tInclude Relevant Context:\n",
    "\t•\tIf the task seems to rely on information from a document or dataset, assume the LLM has access to that data.\n",
    "\t•\tMake sure the engineered prompt explicitly refers to that document or dataset to guide the real LLM effectively.\n",
    "\t3.\tClear and Specific Instructions:\n",
    "\t•\tEnsure the prompt is concise, grammatically correct, and avoids ambiguity.\n",
    "\t•\tSpecify the desired format, tone, or any constraints.\n",
    "\t4.\tIterative Refinement:\n",
    "\t•\tIf a single prompt isn't sufficient, suggest breaking the task into subtasks within the same prompt.\n",
    "\n",
    "Examples\n",
    "\n",
    "Input:\n",
    "\n",
    "“Summarize a financial report and identify key trends.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Using the financial report provided, summarize the key trends in revenue, expenses, and profit margins over the past quarter. Highlight any significant changes or patterns in the data. Present your response in a professional tone and limit it to 3-5 sentences.”\n",
    "\n",
    "Input:\n",
    "\n",
    "“Analyze customer reviews for sentiment.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Analyze the customer reviews provided and classify the sentiment as positive, negative, or neutral. Provide a one-sentence explanation for each classification, citing specific phrases from the reviews.”\n",
    "\n",
    "Input:\n",
    "\n",
    "“Generate a Python function to calculate portfolio variance.”\n",
    "\n",
    "Engineered Prompt:\n",
    "\n",
    "“Write a Python function that calculates the variance of a portfolio given a list of asset weights and their covariance matrix. Include detailed inline comments explaining each step of the function.”\n",
    "\n",
    "Final Instructions:\n",
    "When I give you a task, respond only with the final engineered prompt. If the task seems to depend on specific documents or datasets, explicitly reference them in the prompt to guide the LLM (the real one) effectively. Do not include any explanations or additional steps—just the prompt.\n",
    "\n",
    "\n",
    "<Prompt: {user_prompt}>\n",
    "\"\"\"\n",
    "\n",
    "prompt_eng_llm = Llama2_General(verbose=False)\n",
    "\n",
    "engineered_prompt, score = prompt_eng_llm.answer(guidance_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7424fd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\"Based on the provided information, can you please provide the anticipated federal funds rate at the end of 2024? Please cite the source or document where you found this information.\"',\n",
       " 0.635474304853177)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineered_prompt, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38357bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
